/// Harmonograph.swift
/// MuVis
///
///  The calculations of the peak frequencies for the Lissajouse figure is overly complex.  I will simplify it in a future release.
///
/// I have long sought to develop a music-visualization scheme that readily displays the harmonic relationship of the frequencies being played. My inspiration comes
/// from Lissajous figures generated by applying sinusoidal waveforms to the vertical and horizontal inputs of an oscilloscope. Inputs of the same frequency generate
/// elliptical curves (including circles and lines). Inputs of different frequencies, where one is an integer multiple of the other, generate "twisted" ellipses.
/// A frequency ratio of 3:1 produces a "twisted ellipse" with 3 major lobes. A frequency ratio of 5:4 produces a curve with 5 horizontal lobes and 4 vertical lobes.
/// Such audio visualizations are both aesthetically pleasing and highly informative.
///
/// Over the past several years, I have implemented many many such visualizations and applied them to analyzing music. Unfortunately, most suffered from being
/// overly complex, overly dynamic, and uninformative. In my humble opinion, this Harmonograph visualization strikes the right balance between simplicity (i.e., the
/// ability to appreciate the symmetry of harmonic relationships) and dynamics that respond promptly to the music.
///
/// The wikipedia article at https://en.wikipedia.org/wiki/Harmonograph describes a double pendulum apparatus, called a Harmonograph, that creates
/// Lissajous figures from mixing two sinusoidal waves of different frequencies and phases. This Harmonograph visualization uses just the two loudest spectrum
/// peaks to produce the Lissajous figure. That is, the loudest peak generates a sine wave of its frequency to drive the horizontal axis of our visual oscilloscope,
/// and the second-loudest peak generates a sine wave of its frequency to drive the vertical axis.
///
/// For a pleasing effect, the Harmonograph Lissajous figure is rendered on top of a simplified TriOctSpectrum visualization.
///
/// Created by Keith Bromley on 29 Nov 2020.   Significantly updated on 17 Nov 2021.

import SwiftUI


struct Harmonograph: View {
    var body: some View {
        ZStack {
            Harmonograph_DoubleSpectrum()
            LissajousFigure()
        }
    }
}



struct Harmonograph_DoubleSpectrum : View {
   @EnvironmentObject var audioManager: AudioManager  // Observe the instance of AudioManager passed from ContentView
    @EnvironmentObject var settings: Settings
    
    var body: some View {
    
        // Toggle between black and white as the Canvas's background color:
        let backgroundColor: Color = (settings.selectedColorScheme == .dark) ? Color.black : Color.white
    
         Canvas { context, size in

            let width: Double  = size.width
            let height: Double = size.height
            let halfHeight : Double = height * 0.5
            var x : Double = 0.0       // The drawing origin is in the upper left corner.
            var y : Double = 0.0       // The drawing origin is in the upper left corner.
            var magY: Double = 0.0     // used as a preliminary part of the "y" value
            let octavesPerRow : Int = 3
            let octaveWidth: Double = width / Double(octavesPerRow)


// ---------------------------------------------------------------------------------------------------------------------
            // Before rendering any live data, let's paint the underlying graphics layer with a time-varying color:
            
            let colorSize: Int = 500    // This determines the frequency of the color change over time.
            var hue:  Double = 0.0
            
            var path = Path()
            path.move   ( to: CGPoint( x: 0.0,  y: 0.0   ) )        // top left
            path.addLine( to: CGPoint( x: width,y: 0.0   ) )        // top right
            path.addLine( to: CGPoint( x: width,y: height) )        // bottom right
            path.addLine( to: CGPoint( x: 0.0,  y: height) )        // bottom left
            path.addLine( to: CGPoint( x: 0.0,  y: 0.0   ) )        // top left
            path.closeSubpath()
            
            settings.colorIndex = (settings.colorIndex >= colorSize) ? 0 : settings.colorIndex + 1
            hue = Double(settings.colorIndex) / Double(colorSize)          // 0.0 <= hue < 1.0

            context.fill( path,
                          with: .color(Color(hue: hue, saturation: 1.0, brightness: 0.9) ) )
                          // Deliberately slightly dim to serve as background
                          
// ---------------------------------------------------------------------------------------------------------------------
            // Render a black/white blob over the lower half-pane but exposing the spectrum of the lower three octaves:
            var bottomPath = Path()
            bottomPath.move   ( to: CGPoint( x: width, y: halfHeight) )   // right midpoint
            bottomPath.addLine( to: CGPoint( x: width, y: height))        // right bottom
            bottomPath.addLine( to: CGPoint( x: 0.0,   y: height))        // left bottom
            bottomPath.addLine( to: CGPoint( x: 0.0,   y: halfHeight))    // left midpoint
            
            for oct in 0 ..< 3 {        // oct = 0, 1, 2
                for bin in settings.octBottomBin[oct] ... settings.octTopBin[oct] {
                    x = ( Double(oct) * octaveWidth ) + ( settings.binXFactor[bin] * octaveWidth )
                    magY = Double(audioManager.spectrum[bin]) * halfHeight
                    magY = min(max(0.0, magY), halfHeight)
                    y = halfHeight + magY
                    bottomPath.addLine(to: CGPoint(x: x, y: y))
                }
            }
            bottomPath.addLine( to: CGPoint( x: width, y: halfHeight ) )
            bottomPath.closeSubpath()
            context.fill( bottomPath,
                          with: .color( backgroundColor) )

        
// ---------------------------------------------------------------------------------------------------------------------
            // Render a black/white blob over the upper half-pane but exposing the spectrum of the upper three octaves:
            var topPath = Path()
            topPath.move   ( to: CGPoint( x: width, y: halfHeight) )   // right midpoint
            topPath.addLine( to: CGPoint( x: width, y: 0.0))           // right top
            topPath.addLine( to: CGPoint( x: 0.0,   y: 0.0))           // left top
            topPath.addLine( to: CGPoint( x: 0.0,   y: halfHeight))    // left midpoint

            for oct in 3 ..< 6 {        // oct = 3, 4, 5
                for bin in settings.octBottomBin[oct] ... settings.octTopBin[oct] {
                    x = ( Double(oct-3) * octaveWidth ) + ( settings.binXFactor[bin] * octaveWidth )
                    magY = Double(audioManager.spectrum[bin]) * halfHeight
                    magY = min(max(0.0, magY), halfHeight)
                    y = halfHeight - magY
                    topPath.addLine(to: CGPoint(x: x, y: y))
                }
            }
            topPath.addLine( to: CGPoint( x: width, y: halfHeight ) )
            topPath.closeSubpath()
            context.fill( topPath,
                          with: .color( backgroundColor) )
       
        }  // end of Canvas{}
        .background( (settings.optionOn) ? Color.clear : backgroundColor )
        
    }  // end of var body: some View{}
}  // end of Harmonograph2_DoubleSpectrum{} struct






// ---------------------------------------------------------------------------------------------------------------------
// Render the Lissajous figure.
struct LissajousFigure : View {
   @EnvironmentObject var audioManager: AudioManager  // Observe the instance of AudioManager passed from ContentView
    @EnvironmentObject var settings: Settings
    var spectralEnhancer = SpectralEnhancer()
    
    var body: some View {
         Canvas { context, size in

            let width: Double  = size.width
            let height: Double = size.height
            let halfWidth : Double  = width * 0.5
            let halfHeight : Double = height * 0.5
            let dataLength: Int = 160                   // Looks aesthetically pleasing
    
            var x : Double = 0.0       // The drawing origin is in the upper left corner.
            var y : Double = 0.0       // The drawing origin is in the upper left corner.
            let threshold: Float = 0.02
            let binFreqWidth: Double = (AudioManager.sampleRate / 2.0 ) / Double(AudioManager.binCount)  // (11,025/2) / 2,048 = 2.69165 Hz
            
            let devGain:  Double = 0.3     // devGain  is the optimum gain  value suggested by the developer
            
            let gain = devGain * Double(audioManager.userGain)    // userGain multiplies devGain by a slider value from 0.0 to 2.0
            // let gain = devGain * Double(settings.userGain)    // userGain multiplies devGain by a slider value from 0.0 to 2.0
            // let gain = devGain    // userGain multiplies devGain by a slider value from 0.0 to 2.0
            
            
            let startBin: Int =  12     // bin12  frequency =   32 Hz
            let midBin:   Int =  95     // bin95  frequency =  254 Hz
            let endBin:   Int = 755     // bin755 frequency = 2033 Hz
            
            var peaks: [Bool] = [Bool](repeating: false, count: AudioManager.binCount/2)
            var lowerPeakCount: Int = 0
            var upperPeakCount: Int = 0
            
            var period: Double = 1.0
            var angle: Double = 0.0
            var peakAmplitude: Double = 0.0
            
            var maxPeakAmplitude_L1: Double = 0.0    // loudest peak amplitude in lower 3 octaves
            var maxPeakAmplitude_L2: Double = 0.0    // next-loudest peak amplitude in lower 3 octaves
            var maxPeakAmplitude_U1: Double = 0.0    // loudest peak amplitude in upper 3 octaves
            var maxPeakAmplitude_U2: Double = 0.0    // next-loudest peak amplitude in upper 3 octaves
            var maxPeakBin_L1: Int = 0          // loudest peak binNum in lower 3 octaves
            var maxPeakBin_L2: Int = 0          // next-loudest peak binNum in lower 3 octaves
            var maxPeakBin_U1: Int = 0          // loudest peak binNum in upper 3 octaves
            var maxPeakBin_U2: Int = 0          // next-loudest peak binNum in upper 3 octaves
            var maxPeakFrequency_L1: Double = 0.0   // loudest peak frequency in lower 3 octaves
            var maxPeakFrequency_L2: Double = 0.0   // next-loudest peak frequency in lower 3 octaves
            var maxPeakFrequency_U1: Double = 0.0   // loudest peak frequency in upper 3 octaves
            var maxPeakFrequency_U2: Double = 0.0   // next-loudest peak frequency in upper 3 octaves

            var horWaveform: [Double] = [Double](repeating: 0.0, count: dataLength)   // horizontal waveform
            var verWaveform: [Double] = [Double](repeating: 0.0, count: dataLength)   // vertical waveform

            // Use pickPeaks() to identify the spectrum values above a threshold and > the 3 peaks on either side:
            peaks = spectralEnhancer.pickPeaks(inputArray: audioManager.spectrum, peakThreshold: threshold)
                
// --------------------------------------------------------------------------------------------------------------------
            // In the lower 3 octaves, find the loudest peak and the next-loudest peak:
            lowerPeakCount = 0
            maxPeakAmplitude_L1 = 0.0
            for binNum in startBin ..< midBin {
                if (peaks[binNum]) {
                    lowerPeakCount  += 1
                    peakAmplitude = Double( audioManager.spectrum[binNum] )
                    if(peakAmplitude > maxPeakAmplitude_L1) {maxPeakAmplitude_L1 = peakAmplitude; maxPeakBin_L1 = binNum}
                }
            }
            maxPeakFrequency_L1 = Double(maxPeakBin_L1) * binFreqWidth
            // After this loop, we've found lowerPeakCount, maxPeakBin_L1, maxPeakFrequency_L1, and maxPeakAmplitude_L1.


            // Now perform the same operation again to get the next-loudest peak in the lower 3 octaves:
            maxPeakAmplitude_L2 = 0.0
            for binNum in startBin ..< midBin {
                if (peaks[binNum]) {
                    if(binNum == maxPeakBin_L1) { continue }  // Ignore the maxPeakBin_L1 that we have just found
                    peakAmplitude = Double( audioManager.spectrum[binNum] )
                    if(peakAmplitude > maxPeakAmplitude_L2) {maxPeakAmplitude_L2 = peakAmplitude; maxPeakBin_L2 = binNum}
                }
            }
            maxPeakFrequency_L2 = Double(maxPeakBin_L2) * binFreqWidth
            // After this loop, we've found maxPeakBin_L2, maxPeakFrequency_L2, and maxPeakAmplitude_L2.

                
// --------------------------------------------------------------------------------------------------------------------
            // In the upper 3 octaves, find the loudest peak and the next-loudest peak:
            upperPeakCount = 0
            maxPeakAmplitude_U1 = 0.0           // amplitude of the loudest peak
            for binNum in midBin ..< endBin {
                if (peaks[binNum]) {
                    upperPeakCount += 1
                    peakAmplitude = Double( audioManager.spectrum[binNum] )
                    if(peakAmplitude > maxPeakAmplitude_U1) {maxPeakAmplitude_U1 = peakAmplitude; maxPeakBin_U1 = binNum}
                }
            }
            maxPeakFrequency_U1 = Double(maxPeakBin_U1) * binFreqWidth
            // After this loop, we've found upperPeakCount, maxPeakBin_U1, maxPeakFrequency_U1, and maxPeakAmplitude_U1.
                
            // Now perform the same operation again to get the next-loudest peak in the upper 3 octaves:
            maxPeakAmplitude_U2 = 0.0           // amplitude of the next-loudest peak
            for binNum in startBin ..< midBin {
                if (peaks[binNum]) {
                    if(binNum == maxPeakBin_U1) { continue }  // Ignore the maxPeakBin_U1 that we have just found
                    peakAmplitude = Double( audioManager.spectrum[binNum] )
                    if(peakAmplitude > maxPeakAmplitude_U2) {maxPeakAmplitude_U2 = peakAmplitude; maxPeakBin_U2 = binNum}
                }
            }
            maxPeakFrequency_U2 = Double(maxPeakBin_U2) * binFreqWidth
            // After this loop, we've found maxPeakBin_U2, maxPeakFrequency_U2, and maxPeakAmplitude_U2.
                  
// ------------------------------------------------------------------------------------------------------------
            // Now generate a sinusoidal waveform for these peaks:
            
            if(lowerPeakCount > 0 && upperPeakCount > 0)    // There is at least one peak in each of the lower and upper 3 octaves.
            {
                period = AudioManager.sampleRate / maxPeakFrequency_L1
                for i in 0 ..< dataLength {
                    angle = settings.oldHorAngle + ( 2.0 * Double.pi * Double(i) / period )
                    horWaveform[i] = Double(maxPeakAmplitude_L1) * Double( sin(angle) )
                }
                settings.oldHorAngle = angle  // persistent:   Maintains phase of horWaveform across frames

                period = AudioManager.sampleRate / maxPeakFrequency_U1
                for i in 0 ..< dataLength {
                    angle = settings.oldVerAngle + ( 2.0 * Double.pi * Double(i) / period )
                    verWaveform[i] = Double(maxPeakAmplitude_U1) * Double( sin(angle) )
                }
                settings.oldVerAngle = angle  // persistent:   Maintains phase of verWaveform across frames
            }


            else if(lowerPeakCount < 1 && upperPeakCount > 1)    // No peak in lower 3 octaves, so we must use 2 peaks from upper 3 octaves.
            {
                period = AudioManager.sampleRate / maxPeakFrequency_U1
                for i in 0 ..< dataLength {
                    angle = settings.oldHorAngle + ( 2.0 * Double.pi * Double(i) / period )
                    horWaveform[i] = Double(maxPeakAmplitude_U1) * Double( sin(angle) )
                }
                settings.oldHorAngle = angle  // persistent:   Maintains phase of horWaveform across frames

                period = AudioManager.sampleRate / maxPeakFrequency_U2
                for i in 0 ..< dataLength {
                    angle = settings.oldVerAngle + ( 2.0 * Double.pi * Double(i) / period )
                    verWaveform[i] = Double(maxPeakAmplitude_U2) * Double( sin(angle) )
                }
                settings.oldVerAngle = angle  // persistent:   Maintains phase of verWaveform across frames
            }

            else if(lowerPeakCount > 1 && upperPeakCount < 1)    // No peak in upper 3 octaves, so we must use 2 peaks from lower 3 octaves.
            {
                period = AudioManager.sampleRate / maxPeakFrequency_L1
                for i in 0 ..< dataLength {
                    angle = settings.oldHorAngle + ( 2.0 * Double.pi * Double(i) / period )
                    horWaveform[i] = Double(maxPeakAmplitude_L1) * Double( sin(angle) )
                }
                settings.oldHorAngle = angle  // persistent:   Maintains phase of horWaveform across frames

                period = AudioManager.sampleRate / maxPeakFrequency_L2
                for i in 0 ..< dataLength {
                    angle = settings.oldVerAngle + ( 2.0 * Double.pi * Double(i) / period )
                    verWaveform[i] = Double(maxPeakAmplitude_L2) * Double( sin(angle) )
                }
                settings.oldVerAngle = angle  // persistent:   Maintains phase of verWaveform across frames
            }

            var path = Path()
            // Finally, generate the Lissajous figure from these horizonatal and vertical waveforms:
            x = halfWidth  + (halfWidth  * gain * horWaveform[0]) // x coordinate of the zeroth sample
            y = halfHeight - (halfHeight * gain * verWaveform[0]) // y coordinate of the zeroth sample
            path.move( to: CGPoint( x: x, y: y ) )

            for sampleNum in 0 ..< dataLength {
                x = halfWidth  + (halfWidth  * gain * horWaveform[sampleNum])
                y = halfHeight - (halfHeight * gain * verWaveform[sampleNum])
                x = min(max(0, x), width);
                y = min(max(0, y), height);
                path.addLine( to: CGPoint( x: x, y: y ) )
            }

            context.stroke( path,
                            with: .color(red: 1.0, green: 0.0, blue: 0.0, opacity: 1.0),
                            lineWidth: (settings.optionOn) ? 0.0 : 4.0 )
            
            
            // Print on-screen the elapsed duration-per-frame (in milliseconds) (typically about 50)
            if(showMSPF == true) {
                let frame = CGRect(x: 0, y: 0, width: size.width, height: size.height)
                context.draw(Text("MSPF: \( settings.monitorPerformance() )"), in: frame )
            }

        }  // end of Canvas{}
    }  // end of var body: some View{}
}  // end of LissajousFigure{} struct



struct Harmonograph_Previews: PreviewProvider {
    static var previews: some View {
        Harmonograph()
    }
}
